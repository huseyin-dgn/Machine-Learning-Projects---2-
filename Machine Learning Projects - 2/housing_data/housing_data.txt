ğŸ“Š Model Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±: KNN vs. Random Forest

âŒ KNN Neden Ä°yi SonuÃ§ Vermedi?
K-En YakÄ±n KomÅŸular (KNN) algoritmasÄ± non-parametrik ve tembel Ã¶ÄŸrenme yÃ¶ntemi olduÄŸu iÃ§in, Ã¶zellikle yÃ¼ksek boyutlu ve karmaÅŸÄ±k veri setlerinde iyi sonuÃ§ vermez.

ğŸ‘‰ KNN Model SkorlarÄ±:
ğŸ† RÂ² (R-kare): 0.68 (DÃ¼ÅŸÃ¼k, model yeterince aÃ§Ä±klayÄ±cÄ± deÄŸil)
ğŸ“‰ MAE: 3.1
ğŸ“Š RMSE: 5.

ğŸ“Œ KNN'nin zayÄ±f olmasÄ±nÄ±n nedenleri:
Ã‡ok deÄŸiÅŸkenli ve karmaÅŸÄ±k veri setlerinde KNN, komÅŸuluk tabanlÄ± bir yÃ¶ntem olduÄŸu iÃ§in yeterince genelleme yapamaz.
GÃ¼rÃ¼ltÃ¼ye duyarlÄ±dÄ±r, Ã¶zellikle dÃ¼zensiz daÄŸÄ±lÄ±ma sahip verilerde kÃ¶tÃ¼ performans gÃ¶sterebilir.
Parametre seÃ§imine baÄŸlÄ±dÄ±r (k deÄŸeri), yanlÄ±ÅŸ k seÃ§imi kÃ¶tÃ¼ sonuÃ§ verebilir.

âœ… Random Forest Neden Daha Ä°yi Ã‡alÄ±ÅŸtÄ±?
Random Forest, birden fazla karar aÄŸacÄ±nÄ± birleÅŸtirerek gÃ¼Ã§lÃ¼ bir Ã¶ÄŸrenme modeli oluÅŸturur. Veri iÃ§indeki farklÄ± Ã¶zellikleri deÄŸerlendirerek daha genelleÅŸtirilmiÅŸ tahminler yapar.

ğŸ‘‰ Random Forest Model SkorlarÄ±:
ğŸ† RÂ² (R-kare): 0.89 (Modelin veriyi aÃ§Ä±klama oranÄ± oldukÃ§a yÃ¼ksek!)
ğŸ“‰ MAE: 2.04
ğŸ“Š RMSE: 2.99

ğŸ“Œ Random Forest'in Ã¼stÃ¼n olmasÄ±nÄ±n nedenleri:
âœ” Ã–zelliklerin Ã¶nemini deÄŸerlendirir ve en iyi deÄŸiÅŸkenleri kullanÄ±r.
âœ” AÅŸÄ±rÄ± Ã¶ÄŸrenmeyi (overfitting) Ã¶nler Ã§Ã¼nkÃ¼ bootstrap Ã¶rnekleriyle Ã§alÄ±ÅŸÄ±r.
âœ” Veri gÃ¼rÃ¼ltÃ¼sÃ¼ne karÅŸÄ± dayanÄ±klÄ±dÄ±r, Ã§Ã¼nkÃ¼ birden fazla aÄŸaÃ§ Ã¼zerinden karar verir.
âœ” BÃ¼yÃ¼k veri setlerinde daha iyi performans gÃ¶sterir, KNN gibi tÃ¼m veriyi hafÄ±zada tutmak zorunda deÄŸildir.

ğŸ¯ SonuÃ§:
ğŸ“Œ KNN yerine Random Forest kullanmak, karmaÅŸÄ±k ve Ã§ok deÄŸiÅŸkenli veri setlerinde daha iyi tahmin yapmamÄ±zÄ± saÄŸladÄ±.
ğŸ” Daha dÃ¼ÅŸÃ¼k hata (MAE, RMSE) ve daha yÃ¼ksek doÄŸruluk (RÂ²) elde ettik! ğŸš€


ğŸ“Œ KOD AÃ‡IKLAMALARI: KNN vs. Random Forest ğŸ“Œ
Bu projede Boston Housing Data kullanarak ev fiyatlarÄ±nÄ± tahmin etmeye Ã§alÄ±ÅŸtÄ±k. Ä°ki farklÄ± model denedik:
1ï¸âƒ£ K-Nearest Neighbors (KNN) Regresyon
2ï¸âƒ£ Random Forest Regresyon

SonuÃ§ olarak Random Forest, KNNâ€™den Ã§ok daha baÅŸarÄ±lÄ± oldu. Åimdi kodlarÄ± detaylÄ±ca aÃ§Ä±klayalÄ±m.

1ï¸âƒ£ Veri HazÄ±rlama

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.read_csv("HousingData.csv")  # Veri setini okuma
df.dropna(inplace=True)  # Eksik verileri temizleme

ğŸ“Œ Ne yapÄ±ldÄ±?
Pandas ile veri okundu.
dropna(inplace=True) ile eksik veriler temizlendi.

2ï¸âƒ£ KNN Modeli ile Tahmin
Veri Setini Train-Test Olarak AyÄ±rma

from sklearn.model_selection import train_test_split
X = df.drop("MEDV", axis=1)  # MEDV hedef deÄŸiÅŸken olduÄŸu iÃ§in Ã§Ä±karÄ±ldÄ±
y = df["MEDV"]  # Hedef deÄŸiÅŸken

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)

ğŸ“Œ Ne yapÄ±ldÄ±?
BaÄŸÄ±msÄ±z deÄŸiÅŸkenler (X) ile baÄŸÄ±mlÄ± deÄŸiÅŸken (y) ayrÄ±ldÄ±.
train_test_split() ile verinin %33'Ã¼ test, %67'si eÄŸitim olarak bÃ¶lÃ¼ndÃ¼.
Verileri Ã–lÃ§eklendirme (StandardScaler)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaler_X_train = scaler.fit_transform(X_train)  # EÄŸitim verisini fit et ve dÃ¶nÃ¼ÅŸtÃ¼r
scaler_X_test = scaler.transform(X_test)  # Test verisini aynÄ± Ã¶lÃ§ekte dÃ¶nÃ¼ÅŸtÃ¼r

ğŸ“Œ Ne yapÄ±ldÄ±?
KNN Ã¶lÃ§ek duyarlÄ± olduÄŸu iÃ§in veriler standartlaÅŸtÄ±rÄ±ldÄ± (z-score normalization).
KNN Modelini EÄŸitme ve Tahmin Yapma

from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

knn = KNeighborsRegressor(n_neighbors=5)  # K=5 olarak seÃ§ildi
knn.fit(scaler_X_train, y_train)  # Model eÄŸitildi
knn_pred = knn.predict(scaler_X_test)  # Test seti iÃ§in tahmin yapÄ±ldÄ±

r2 = round(r2_score(y_test, knn_pred), 2)
mae = round(mean_absolute_error(y_test, knn_pred), 2)
rmse = round(np.sqrt(mean_squared_error(y_test, knn_pred)), 2)

print("KNN SonuÃ§larÄ±:")
print("RÂ²:", r2)
print("MAE:", mae)
print("RMSE:", rmse)

ğŸ“Œ Ne yapÄ±ldÄ±?
KNN modeli eÄŸitildi ve test seti Ã¼zerinde tahmin yapÄ±ldÄ±.
Hata metrikleri hesaplandÄ±:

RÂ² (Model doÄŸruluÄŸu)
MAE (Mutlak hata)
RMSE (KÃ¶k ortalama kare hata)
En Ä°yi K DeÄŸerini Belirleme (Hata GrafiÄŸi)

hata_oranÄ± = []

for k in range(1, 40):
    knn = KNeighborsRegressor(n_neighbors=k)
    knn.fit(scaler_X_train, y_train)
    knn_pred = knn.predict(scaler_X_test)

    err = mean_absolute_error(y_test, knn_pred)
    hata_oranÄ±.append(err)

plt.figure(figsize=(10,6), dpi=200)
plt.plot(range(1, 40), hata_oranÄ±, color="purple", linestyle="dashed",
         marker="s", markerfacecolor="yellow", label='Test Error')
plt.legend()
plt.ylabel('Hata OranÄ±')
plt.xlabel("K DeÄŸeri")
plt.show()

ğŸ“Œ Ne yapÄ±ldÄ±?
FarklÄ± k deÄŸerleri iÃ§in model eÄŸitildi ve hata oranlarÄ± (MAE) hesaplandÄ±.
Grafik Ã§izilerek en iyi k deÄŸeri seÃ§ildi.

3ï¸âƒ£ Random Forest ile Tahmin
Veriyi Tekrar AyÄ±rma (Train-Test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=9)

ğŸ“Œ Ne yapÄ±ldÄ±?
Train-Test ayÄ±rma iÅŸlemi tekrar yapÄ±ldÄ±, ancak bu kez test seti %30 olarak seÃ§ildi.

Hyperparameter Tuning (GridSearchCV)

from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestRegressor

n_est = [100,150,200,250,300]  # AÄŸaÃ§ sayÄ±larÄ±
bootstrap_sec = [True, False]  # Bootstrap Ã¶rnekleme
oob = [True, False]  # Out-of-bag deÄŸerlendirme

parameters = {
    "n_estimators": n_est,
    "bootstrap": bootstrap_sec,
    "oob_score": oob
}

random_forest = RandomForestRegressor()  # Regresyon modeli
grid = GridSearchCV(random_forest, parameters, cv=5, scoring='neg_mean_squared_error')
grid.fit(X_train, y_train)

ğŸ“Œ Ne yapÄ±ldÄ±?

GridSearchCV kullanÄ±larak en iyi hiperparametreler belirlendi:
n_estimators: KaÃ§ aÄŸaÃ§ kullanÄ±lacaÄŸÄ±
bootstrap: TÃ¼m verinin mi yoksa bir kÄ±smÄ±nÄ±n mÄ± kullanÄ±lacaÄŸÄ±
oob_score: Out-of-bag deÄŸerlendirme

Random Forest Modeli ile Tahmin ve Hata Metrikleri

pred = grid.predict(X_test)

mae = mean_absolute_error(y_test, pred)
mse = mean_squared_error(y_test, pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, pred)

print("Random Forest SonuÃ§larÄ±:")
print("Mean Absolute Error (MAE):", mae)
print("Mean Squared Error (MSE):", mse)
print("Root Mean Squared Error (RMSE):", rmse)
print("R-squared (RÂ²):", r2)

ğŸ“Œ Ne yapÄ±ldÄ±?

Random Forest modeli eÄŸitildi ve test seti Ã¼zerinde tahmin yapÄ±ldÄ±.
Hata metrikleri hesaplandÄ±:
MAE: 2.04
MSE: 8.95
RMSE: 2.99
RÂ²: 0.89 (OldukÃ§a yÃ¼ksek doÄŸruluk)

ğŸ“Š SonuÃ§lar: KNN vs. Random Forest

Model	    RÂ² Skoru  MAE	RMSE
KNN	        0.68	  3.1    5.39
Random Forest	0.89	2.04	2.99

âœ… Random Forest, KNNâ€™ye gÃ¶re daha dÃ¼ÅŸÃ¼k hata verdi ve daha yÃ¼ksek doÄŸruluk saÄŸladÄ±.

ğŸ“Œ SONUÃ‡ ğŸ“Œ
âœ” KNN Ã¶lÃ§eklendirme gerektiriyor ve parametreye (k) duyarlÄ±.
âœ” Random Forest daha iyi genelleÅŸtirme yapÄ±yor ve overfittingâ€™i azaltÄ±yor.
âœ” Bu yÃ¼zden Random Forest kullanÄ±mÄ± daha iyi sonuÃ§ verdi. ğŸ¯ğŸš€







